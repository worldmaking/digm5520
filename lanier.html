<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title></title>
<meta name="description" content="">
<meta name="author" content="Graham Wakefield">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<link rel="stylesheet" href="css/basic.css" type="text/css" />
<link rel="stylesheet" href="css/github.css" type="text/css" />
<style>
td { 
	vertical-align: top;
}

img {
	max-height: 75vh;
}

header {
	background-color:#f5f5f5;
	font-size: 75%;
	padding: 0.5em;
}
footer {
	background-color:#f5f5f5;
	font-size: 75%;
	padding: 0.5em;
}
.responsive-google-slides {
    position: relative;
    padding-bottom: 60%; /* 16:9 Ratio = 56.25%, 4:3 ratio = 75% */
    height: 0;
    overflow: hidden;
}
.responsive-google-slides iframe {
	border: 0;
	position: absolute;
	top: 0;
	left: 0;
	width: 100% !important;
	height: 100% !important;
}
</style>
<script src="https://unpkg.com/@stackblitz/sdk/bundles/sdk.umd.js"></script>
</head>
<body class="centremaxwidth960">
<header><a href="index.html">DATT4520 & DIGM5520: Generative Art in Mixed Reality / Spatial Computing in Responsive Environments</a></header>

<h1 id="dawn-of-the-new-everything">Dawn of the new Everything</h1>
<p><a href="https://en.wikipedia.org/wiki/Jaron_Lanier">Jaron Lanier</a>, considered a founder of the field of virtual reality (to whom we owe the term &quot;VR&quot;), and founder of the first VR company &quot;VPL Research&quot;.</p>
<p><a href="https://en.wikipedia.org/wiki/Jaron_Lanier#Dawn_of_the_New_Everything_(2017)">Dawn of the New Everything</a>, 2017.</p>
<p><a href="https://youtu.be/yrGAeHJ2Xg4?t=1730">https://youtu.be/yrGAeHJ2Xg4 29min</a></p>
<p>VPL == <strong>Virtual Programming Languages</strong></p>
<h3 id="unstructured-notes-from-the-book">Unstructured notes from the book:</h3>
<p>1 &quot;everything connects with everything. every tweak of the rules of a new world is a potential setting for a startling, surrealistic bug.&quot;</p>
<p>34 (how scheme of reality seems so unlikely at chemical level; one tweak of laws and all crashes. Lee Smolin proposed universes could evolve, to settle on particles with interesting properties. </p>
<p>47 &quot;The substitution of the interface between a person and the physical environment with an interface to a simulated environment.&quot;</p>
<p>48 for VR to work, when turn head left, images have to turn right, etc, as quickly as possible so you don&#39;t notice. That is, a &quot;mirror image of a person&#39;s sensory and motor organs, or if you like, and inversion of a person&quot;. </p>
<p>51 Verb not noun: body &amp; brain constantly probing and testing reality, reality is what pushes back. for brain, reality is the expectation of what the next moment will be like, but that expectation must be constantly adjusted. &quot;A sense of cognitive momentum, for moment-to-moment anticipation, becomes palpable in VR.&quot; &quot;VR is not really about simulating reality, really, but about stimulating neural expectations.&quot;</p>
<p>VR8: &quot;Technology that rallies the brain to fill in the blanks and cover over our mistakes of a simulator, in order to make a simulated reality seem better than it ought to.&quot;</p>
<p>53 Camera on tripod takes better images than in hand, but opposite is true for eyes. An immobile head (tripod) finds it harder to understand, and in fact, will stop being able to see. vision depends on continuous experimentation largely by head movement. these tiny head movements also communicate huge amounts between people (micro-gestures). Vision works by noticing changes instead of constancies, which requires expectation (to compare to). your nervous system acts like a little scientific community. it is voraciously curious, constantly testing out ideas about what&#39;s out there. VR succeeds when it temporarily convinces this community to rally behind an alternate hypothesis. &quot;once the nervous system has been given enough cues to treat the virtual world as the world on which to base expectations, VR can start to feel real, realer than it ought to.&quot; nervous system is holistic, chooses one external world at a time to believe in. [XR? distinct modalities?] VR system needs to take nervous system over threshold to make it believe virtual world is the one. </p>
<p>VR10: &quot;Reality, from a cognitive point of view, is the brain&#39;s expectation of the next moment. In VR, the brain has been persuaded to expect virtual stuff instead of real stuff for a while.&quot;</p>
<p>VR connects to many disciplines. </p>
<p>VR as a palette cleanser: after being in virtuality for a while, nervous system adapts to it; so coming back to reality makes you appreciate reality in greater detail for a while. the revelatory return. </p>
<p>55 In daily life we get used to the miracle of being alive. it feels ordinary. can start to feel that world, and ourselves, are mechanical. VR exposes you to yourself.</p>
<p>VR12: &quot;VR is the technology of noticing experience itself&quot;. </p>
<p>&quot;by pushing tech as far as possible we can rediscover something in ourselves that transcends technology.&quot;</p>
<p>60 (Daydreaming what VR might be like) program through dancing; make music with my friends by growing imaginary plants</p>
<p>Early computers worked via punch cards passed to technicians. discrete steps of input, processing, output. early formal models of computing from Turing, von Neumann, first expressed around this model. but what if computers were running all the time, interacting with the world, embedded in the world? &quot;this is exactly what Ivan Sutherland prototyped!&quot;</p>
<p>Cybernetics from cyber, steer: when sailing must constantly adjust to environment. computers&#39;s sensors and actuators are its [Umwelt]. compare to a skinner box -- essentially the same. Thus VR could be the most perfect, evil skinner box to reprogram people.</p>
<p>115 &quot;I was not the only person obsessed with he possibility that programming could be made more visual and intuitive. I had read about Scott Kim in Godel Escher Bach, and I knew Warren Robinette from his wonderful video games. (Scott Kim known for symmetrical calligraphy, mathematical dance troupe, and visual programming. Robinette created Rocky&#39;s Boots, one of the first &#39;maker&#39; video games in which players write visual programs on 8-bit computers.) We&#39;d meet and work into the night, drawing sketches of how people might invent digital worlds to connect with one another. One of my weird little projects was a purely sonic general purpose programming language with no connection to vision at all, operated entirely by singing.</p>
<p>123 About accelerationism. Chips get faster but UI doesn&#39;t. chips get faster because we can be precise, nail it down. UI about people, in the big unfenced world, can&#39;t be specified precisely. no way to make same learning curve. other speaker: &quot;if you&#39;re right we better find a way to constrain people more or the world will never get more efficient&quot; hard to argue with god of optimization. we shouldn&#39;t optimize people.</p>
<p>128 Input is not graphics/display; your input in VR is <em>you</em>. </p>
<p>Spherical video? If you can&#39;t reach out and do things, then you are not connected to the fabric of the world around you, you are alone and apart. a phantom that can&#39;t even haunt.</p>
<p>140 most people can learn to embody lobster avatar with ease. I call it homuncular flexibility (plasticity would have been better) </p>
<p>141 &quot;anti-phantom&quot; limbs are quite easy to do. Jim Bower suggests range of usable nonhuman avatars might be related to phylogenetic tree. 
maybe usable weird avatars foretell creatures we are pre-evolved to inhabit. </p>
<p>always imagined mature VR to be NOT a virtual place to visit, but a form you turn into. there&#39;s no absolute distinction between world and avatar in VR. if the clouds turn when your wrist does, you gradually absorb them into your body map. still mostly unexplored wilderness.</p>
<p>167 The phenotropic vision would take generations to realize
they coded a new language called Body Electric which blended high level incremental compiler with data-flow programming. Max/MSP name-checked here.</p>
<p>172 80s Multi-person VR. eerie that minimal tracking, very low quality graphics, human being comes through.
if you recorded their motion &amp; played it back, it would be apparent that they are not there. things were dramatically different if you are aware of each other, moment to moment.
parallels long-standing results in perception of biological motion: black-costumed individuals with just a handful of markers can be identified as people, in sex, mood, etc. just from a few dots in motion. [referring to Gunnar Johansson&#39;s 1970&#39;s work]
avatars are interactive versions of these experiments
visceral realness of human presence as most dramatic sensation he has felt in VR</p>
<p>199 gadget spectrum diagram (axes: distance to perception, and with/without real)</p>
<p>202 Allosphere mention</p>
<p>233 Core of VR is interactivity; even with poor graphics (1980&#39;s) could give compelling experience
used cliches still in use today, e.g. virtual rendering of actual room demo is given in</p>
<p>235 advice for VR designers/artists
a) your most important canvas is not the virtual world, but the sensorimotor loop. stretch it, shrink it, twist it, interlace it with loops from other people
b) emphasize biological motion over rigid UI elements that throw away most of what the body does. the worst offender is a button. use continuous controls.
c) avoid VR cliches; trapdoors, objects flying at your face etc. or find ways to use them to serve a higher purpose
d) test world with diverse people, add diverse people to team; backgrounds have a bigger impact on VR. 
e) question received wisdom about VR (science is young) and especially who it is for
f) narrative arc is in real world, not virtual: think about overall experience (before/after headset): expectations going in, feelings coming out.
g) resist whatever is easiest to achieve with your tools
h) think about other people in the real but not virtual space. are they part? are they watching, or in common causality?
i) fight against film school impulses. watcher is invisible in film, but not in VR. navigable world is less important than body. what do they see when they look at their hand, in a mirror: if not part of the story, then not yet VR.
j) fight against gaming impulses. thrilling games on screen become dull, isolating in VR. you are no longer bigger than screen; shooting/chasing becomes inverted.
k) must be able to leave a mark, &#39;dent the universe&#39;
l) not everything needs to be algorithmic/automatic. niche for live performers [See Ken Perlin&#39;s work]
m) think about hazards &amp; safety; cables, spinning, tripping, 
n) worry about power dynamics and potential for abuse, but not at expense of daring thoughts about how future can be better
o) don&#39;t agree with me or anyone else; think for yourself</p>
<p>245 Novels: The Machine Stops (Forster), True Names (Vinge), Neuromancer (Gibson). </p>
<p>276 &quot;Sound of one hand&quot; demo in &#39;92 at SIGGRAPH. Used 1 dataglove. Had 1 month the design musical performance system, and performance. Audience also saw his perspective on big screen. Every note generated by hand movements. No predetermined sequences. Starts with minimal demo phase to convince audience interaction is real. Rhythm Gimbal instrument; looked like gyroscope, when picked up &amp; moved emitted sound, triggered by rings rubbing against each other (also changing colour at contact). once started it would slow down, but over a long time, so it would continue to make sounds when not being attended to, making a backdrop to play other instruments over. range of harmonic/textural styles, from calm to crazed dissonance. works well but not self-sufficient algorithmic music generator: necessary element of intuitive performance in finding the weird harmonies. hard to get a specific chord, but could get a feel out of a chord progression, by influencing when chords change and how radical the changes are; not less control, but a different kind of control. test of an instrument is not what it can do, but whether you can become infinitely more sensitive to it as you explore and learn. a good instrument has a depth that the body can learn, that the verbal-visual mind cannot. 
demo unexpectedly turned into an actual expressive performance, but it reflected his spiritual experience at the time. other instruments floated inside hollow asteroid, him flying around them. audience unseen. 
&quot;computer music, because of its coded nature, can&#39;t help but use instruments that are built out of concepts of what music is.&quot; drastic departure from &#39;dumb&#39; instruments of past. piano doesn&#39;t know what notes are. instruments with mandatory concepts built in dull the sensitive and sense of awe at the mystery of life at the heart of art &amp; science. If you pretend that what you can code reflects complete understanding of what you can do, you lose sight of the mystery at the edges of everything; this can lead to nerdy, bland art. for computer art/music to work, have to be extra careful to put people and human contact at the centre of attention.
tech here didn&#39;t elevate me as super-god, but made me vulnerable in front of audience; makes a more authentic performance. </p>
<p>279 this performance signalled end of VPL era.</p>
<p>Appendix 1 - Post-symbolic communication</p>
<p>292 hands and tongues are our appendages that can move at speed of thought. we built everything with hands, coordinated by tongues. speak to plan what make with hands.
tongues (language) let us manipulate at speed of thought to invoke &quot;illusions of all the other manipulations of reality that we can only achieve very slowly and with a lot of work&quot;. Giant amethyst octopus is throwaway gesture, but would be immense work to realize.
language is about haste.
&quot;a symbol is a trick for the sake of efficiency&quot;, lets us express thoughts to others about as fast as they are experienced, without all the work in reality. turns part of the world we can control (tongue) into &quot;invoker of the rest of the universe, and all possible universes, that we cannot control in haste&quot;
imagine future VR, in which can make fresh stuff that works as well, and as quickly, as musical instruments do today. pick up virtual instrument and play, and &quot;it will spin out virtual octopus houses and worlds of other fantastic things with the ease and speed that a saxophone can spin out notes today&quot;
a new trick in the repertory of the species. &quot;same parts of your body that were used to make language possible will be leveraged to make the stuff of experience, not symbolic references to hypothetical experiences.&quot;
take time to learn how (same as instruments, languages), but payoff: other people will experience what you breathed into being; spontaneous inventions objectively there, shared
VR would then combine physical reality (shared), language (expressible at speed close to thought), and imagination (unbounded variety), in a completely new way; calls it post-symbolic communication. </p>
<p>295 footnote: used to have to challenge primacy of abstraction and symbols, but nowadays (after imagenet ML etc.) have opposite problem. replicating recognition of cats &amp; dogs doesn&#39;t mean you understood cognition. we forget that we don&#39;t understand. we can understand math, but we don&#39;t yet understand understanding. Deepnet image ran in reverse didn&#39;t spit out platonic dogs &amp; cats, but something very surreal. </p>
<p>298 talked about toddlers, cephalopods, and fantastic experiences to propose alternate ramp of progress than the dominant narrative in tech, he calls it the McLuhan ramp in honour of Marshall: innovating new ways of connecting to each other. </p>
<p>footnote; check out William Bricken&#39;s exploration of post-symbolic approaches to math in Iconic Mathematics.</p>
<p>299 finite &amp; infinite games</p>
<p>Appendix 2: Phenotropic fevers</p>
<p>301 Software dev has two modes, like caterpillar and butterfly, taking code back &amp; forth between tweak &amp; play. in a given moment a programmer is either writing code or observing it run
(exceptions like Minecraft)
Feels inadequate for VR, because VR doesn&#39;t run in an external box, you are in it, it is you.
Consider kitchen, you don&#39;t stop to reprogram your hands to use spatula, whisk, etc.; you just do one thing then another in same world; modeless. (reference to Larry Tesler&#39;s &quot;no modes&quot;, because modes make things harder to use)
(A modeless VR is editable from within.)
Mode-switching between editing &amp; running has the core pattern of programming since its inception, mostly invented by Grace Hopper. 
Source code is like a legal document for action to avoid failure. Not so much a command of what machine should do, but more like learning to think with robotic precision; become a robot to control a robot. </p>
<p>303 text based code privileges one particular abstraction above others, which becomes the vocabulary; making abstractions seem fundamental &amp; unavoidable. </p>
<p>earliest computers included a visual display mainly to show the bits flipping moment to moment, to watch the program&#39;s state as it runs. [in fact some early computers (late 40&#39;s, Manchester) used CRT displays (Williams Tubes) to actually store data, not just represent it; though soon a secondary CRT would duplicate this and be used to &quot;monitor&quot; the memory. CRT could also be interactive, using a light gun. Memory, display, and input all in one!] good to think about computing in these material terms.</p>
<p>[aside; not only is this somehow reminiscent of NNs now, it is also reminiscent of A-life systems like CA and Tierra.]</p>
<p>Imagine if this path had continued, so you could paint &amp; repaint bits on a screen, so a program can be redone as it runs. but how do you know the meaning of each bit? how do you prevent it from crashing? Image arrangement would have to be designed for human meaning, and painting methods would have to be carefully constrained. Possible, practical, desirable? </p>
<p>304 Source code is not down-to-earth like that, it is full of abstractions that we have to commit to so consistently that we start to believe in them [interestingly this parallels perceptual insight of how VR works, made early in book] </p>
<p>divide between coding &amp; running was side-effect of text-based code, it isn&#39;t intrinsic to computation. how could we change bits of program, while it is running, without having to commit to immobile abstractions? </p>
<p>305 if we could, programming could be more experimental and intuitive; programming as a way to express worlds, systems, experiences, new levels of meaning. Lanier calls this phenotropic (sometimes also called neuromimetic or organic) programming; suggests surface turning toward each other.</p>
<p>VPL&#39;s virtual world software, contents and rules of a world could be changed in any way, fundamentally, while you were in the world. (achieved in a tricky misdirection scheme of swapping out bit patterns when processor wasn&#39;t looking at them [Sightline resonance] and doing so carefully enough to avoid a crash. related to a trick used to make machines perform faster [it is basically the dynamic loading that is needed for JIT]). </p>
<p>calls phenotropic components &quot;editors&quot;.  don&#39;t have to look at same format of source code over and again. different, specialized user experiences for different aspects/kinds of programs. each design is an editor. editor might look like image on a screen (like CRT bits), might look like objects in a world; it is a mapping between the interface experience and the bit patterns underneath. the bit patterns need to be presented in a way you understand how to make changes to them. different editors can point at same bits but present in different ways; maze, trees, etc. (different to fixed abstractions in a programming language). [so far sounds like projectional editors plus visual programming.]</p>
<p>308 VPL worlds being designed in VR were code-less. Code was used to get the system started, but worlds didn&#39;t run on code, only bit patterns modified by editors that mapped to them. 
today &#39;code&#39; seems synonymous with &#39;computing&#39; but need not be. 
(editors could even &quot;simulate&quot; code through a particular mapping.)
of all the mappings they used, a favourite principle was data-flow, but it wasn&#39;t fundamental.</p>
<p>309 VPL had to switch to screen-based because too expensive to have everyone in VR. Their screen-based interface looked like Max. (footnote notes that Max roughly mimics programming old synthesizers of Moog and Buchla. Mentions a &quot;crew&quot; of computer music pioneers including Max Matthews, Buchla, Linn, McMillen, etc. that were his model for starting the VR industry.)
hurts that they had to do that, and hurts that today everyone is using conventional code on screens to develop for VR. its like trying to learn a foreign language from a book without ever talking to a native.</p>
<p>scaling up editors: can one editor edit another editor? yes, that&#39;s the idea. towers and webs of editors. </p>
<p>310 More: editors don&#39;t need to adhere to fixed principles to do so, because they are a UI. so editors need only act like humans to operate other editors. E.g. if one editor has push buttons, another editor can press those buttons, by simulating user interaction.
no need for a shared abstraction [this seems a bit tenuous]. editors need to figure out how to work another editor&#39;s UI [here he is actually talking about model learning; editors really do need to figure out another editor by trial &amp; error]. imagine each editor having a simulated person sticking out of the back, plugging into the next editor&#39;s UI. </p>
<p>311 unlike AI that turns to face you as equal (or superior), pheno simulated human turns away from you, under your control, clearly a tool not an equal</p>
<p>benefits: usability/learnability. every part of system is human manipulable; UI all the way down. each part of system is designed at scale of human use, coarser chunking rather than a zillion abstract functions. thus easier to maintain. allows you to put yourself anywhere in the program and play, experiment.
principle: if you make computer efficient but this makes it harder for people to understand/maintain it, the computer actually becomes inefficient, as there are more likely unforeseen bugs, exploits, or just too much cruft impedance.</p>
<p>312 inverts the perfectionism: bit-perfect routines are only used inside a particular editor, but interfaces between editors are of the fuzzy-robust nature that humans inhabit (contrasts mainstream programming that lays bit-perfect requirement over entire system).
he&#39;s suggesting the joins between editors, the simulated human to UI bridge, actually performed by machine vision/learning. works like an air gap for security too. there are no abstract messages. hope was for machines that would recognize similarity, not just identity. </p>
<p>313 but in 80&#39;s this wasn&#39;t possible, so they did have abstract &#39;press button&#39; message passing events. (their scheme described everything you could see in world in terms of five primitives, including containment, order, etc. which sounds like a scene graph. even in-world code was just objects in this system mapped to underlying bits.) </p>
<p>314 going forward, face tracking. still disturbing though, in terms of surveillance etc. </p>
<p>ideal was a no-API programming interface. editor can&#39;t tell whether it is a human or another editor manipulating it.</p>
<p>316 idea is that AI for the joins between systems will help avoid catastrophic failures. inefficient for small systems, but the brittleness of connection is a major problem for current large systems; ends up more inefficient because of failures (virus, update/obsolescence, etc.) software goes obsolete (unusable) if the protocols etc. they depend on around them inevitably evolve, sometimes even by small amounts. [software doesn&#39;t exist in the abstract timeless vacuum of a compiler&#39;s run, but in a huge messy context of reality]. example of thousands of $ of audio plugins that no longer work, whereas all his older hardware devices that do the same things (some with chips) from the 70s still work. Difference is the analog signal &quot;air gap&quot; between them. [so, a hardware modular synth is the phenotropic version, software plugins are the protocol version. but, it&#39;s not the fact that it is hardware, it&#39;s the fact of the robust air gap.]</p>
<p>317 software is brittle, breaks before it bends. contrast this with natural systems. genetics are sometimes an exception here, but overall it is very robust. [well, it&#39;s had millennia to self-optimize robustness...] partly it works because, mostly small edits make small changes [again, this is only true in certain parts of our DNA, and those parts are evolved to be more mutable than the more catastrophic ones. What this calls for is evolving protocols that build in knowledge of where they can be robustly modified.] thus, in phenotropics, working principle: small changes in editor should map to small changes in behaviour, and never to catastrophe [thought that was an intractable problem?]</p>
<p>319: mature VR should be a fusion of cinema, programming, and jazz. now kids can improvise somewhat in builder games like Minecraft, but deeper improvisatory programming remains elusive. in theory, deep learning could bridge our gap between dancing and evolving a program/world; to bring world-making up to the speed of thought. </p>
<p>could programming ever be real-time? [kind of a goal in live coding]. worked on idea of letting people &#39;feel out&#39; programs rather than line-by-line coding. e.g. being selective instead of constructive. 
sonic analogy: start with cacophony, but when user moves hand, that moment&#39;s sound starts to loop, and other moments&#39; sounds get a bit quieter; repeat this process to select more sounds to join the loop while others fade away. at the end, the performer (could be non-musician) has created their own composition that will be more novel and diverse than a typical GarageBand first piece. 
Similar for visual design: pinch interesting swirls passing in a windy world to solidify them, over and again until a sculpture forms. kind of active, from nothing version of Rorschach test.
Could this analogy be applied to programs? main problem is that it takes more time to observe behaviour. 
No time to observe a million behavioural variations to pick best. Suppose you see thousands of flying turtles in a turtle behaviour cloud, pick those within the storm that seem most salient. [Can&#39;t ML help here in identifying and dimension-reducing the salient regions of different behaviour?]</p>
<p>320 Music instruments are most advanced technical forms of expression so far (talking about non-digital ones here). 
Jazz improvisation is an amazing process of real-time problem solving; programming should be more like jazz. </p>
<p>321 need to design editors that convey range of what a program can do in a convenient viable manner. </p>
<p>Established way we cope with large spaces of possibility is through abstraction. Open Q is whether there&#39;s a more fluid form of concrete expression that can become a practical alternative to abstraction. </p>
<p>Ivan Sutherland has been pursuing fully asynchronous computer architectures for years. Ted Nelson is still working on Xanadu, a www in which links are bidirectional. </p>
<p>322 to an alien, there&#39;s no difference between smartphone and lava lamp. Both get hot and have patterns over them. Maybe we can&#39;t find alien life because we don&#39;t share enough culture to see them. Encryption is a form of culture. </p>

<footer>DATT4520/DIGM5520 2021-22</footer>
</body>
<script src="js/connect.js"></script>
</html>